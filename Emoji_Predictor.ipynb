{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emoji Predictor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMslm0AcmA/fkL7IpOEDT6s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kirtiman24/Emoji_Predictor/blob/master/Emoji_Predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bRgayRbxTO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85bpDohp54CX",
        "colab_type": "text"
      },
      "source": [
        "**Installing the emoji package**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHMpYEl7cyrT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "4335b3f2-e62a-4f0b-93a1-5a9a054bab18"
      },
      "source": [
        "!pip install emoji"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting emoji\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz (43kB)\n",
            "\r\u001b[K     |███████▌                        | 10kB 20.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 30kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 40kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-0.5.4-cp36-none-any.whl size=42176 sha256=e9adda3349e74b7e0ccf0f74481701195089536e2b7f5987c31d9271e12c0355\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/a9/0a/4f8e8cce8074232aba240caca3fade315bb49fac68808d1a9c\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-0.5.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmdO6IGfc70u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import emoji as emoji"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIEUb9rmeAjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train=pd.read_csv('/content/ET 2.csv',header=None)\n",
        "\n",
        "test=pd.read_csv('/content/ETEST .csv',header=None)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TwMIKrteN5j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "bc0676bd-2134-4339-c5ee-f1eed8334c46"
      },
      "source": [
        "train.head(5)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>never talk to me again</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I am proud of your achievements</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It is the worst day in my life</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Miss you so much</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>food is life</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 0  1\n",
              "0           never talk to me again  3\n",
              "1  I am proud of your achievements  2\n",
              "2   It is the worst day in my life  3\n",
              "3                 Miss you so much  0\n",
              "4                     food is life  4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cdayyoCeQ6-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "77b30943-ba12-4929-c372-d7aa84d789b3"
      },
      "source": [
        "test.head(5)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I want to eat</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>he did not answer</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>he got a raise</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>she got me a present</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ha ha ha it was so funny</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          0  1\n",
              "0             I want to eat  4\n",
              "1         he did not answer  3\n",
              "2            he got a raise  2\n",
              "3      she got me a present  0\n",
              "4  ha ha ha it was so funny  2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uGHkb1ueWkN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emoji_dictionary = {\"0\": \"\\u2764\\uFE0F\",   \n",
        "                    \"1\": \":baseball:\",\n",
        "                    \"2\": \":beaming_face_with_smiling_eyes:\",\n",
        "                    \"3\": \":downcast_face_with_sweat:\",\n",
        "                    \"4\": \":fork_and_knife:\",\n",
        "                   }\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AE4x6_UzfT-q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3cf941fe-6b69-4e69-829c-f0d1fd5fff24"
      },
      "source": [
        "emoji.emojize(\":beaming_face_with_smiling_eyes:\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'😁'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwA8kxFbfbsP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "550ad09c-3e65-4178-a5e9-ee940684a058"
      },
      "source": [
        "for e in emoji_dictionary.values():\n",
        "    print(emoji.emojize(e))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "❤️\n",
            "⚾\n",
            "😁\n",
            "😓\n",
            "🍴\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQqNezcbfl3F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ae7a2bfb-3a22-46d0-d4d8-b7e6abc03028"
      },
      "source": [
        "data = train.values\n",
        "for i in range(5):\n",
        "    print(data[i][0],emoji.emojize(emoji_dictionary[str(data[i][1])]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "never talk to me again 😓\n",
            "I am proud of your achievements 😁\n",
            "It is the worst day in my life 😓\n",
            "Miss you so much ❤️\n",
            "food is life 🍴\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS-4S9WBgG2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RraQKR2m5rmD",
        "colab_type": "text"
      },
      "source": [
        "**Preparing the target variable by converting it into the categorical variable**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_F1qwfXxbRc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "150ebbe4-0d2a-4e63-c42f-3dd0dc28d9ab"
      },
      "source": [
        "y_train=to_categorical(train[1][:100])\n",
        "y_cv=to_categorical(train[1][100:])\n",
        "y_test=to_categorical(test[1])\n",
        "print(y_train.shape)\n",
        "print(y_cv.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 5)\n",
            "(32, 5)\n",
            "(56, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtNcRiHf2P2K",
        "colab_type": "text"
      },
      "source": [
        "**Preparing input data to be fed into the LSTM RNN layer.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQW0HK9Vnviz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = Tokenizer()\n",
        "t.fit_on_texts(train[0])\n",
        "vocab_size = len(t.word_index) + 1\n",
        "encoded = t.texts_to_sequences(train[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzp0HnarvssL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "477694c2-e81a-45e7-ebd7-303d579d83b2"
      },
      "source": [
        "#Carrying out padding of the input data to preserve the integrity of the original data \n",
        "padded = pad_sequences(encoded, maxlen=25, padding='post')\n",
        "print(padded[:5])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[83 84  9 15 52  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0]\n",
            " [ 1  6 53 28 18 85  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0]\n",
            " [16  3  4 86 54 55 10 34  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0]\n",
            " [35  2  7 87  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0]\n",
            " [22  3 34  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWn0kAwXwU7e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "84fc9240-2287-45a3-ca8b-05752b88d5ab"
      },
      "source": [
        "x_train_padded=padded[:100]\n",
        "x_cv=padded[100:]\n",
        "x_train_padded.shape\n",
        "x_cv.shape\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 25)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PK4cXQUp2Vfh",
        "colab_type": "text"
      },
      "source": [
        "**Using pre-trained glove embeddings containig 50 dimensional matrix.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vGlrDtZwdMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings_index = dict()\n",
        "f = open('glove.6B.50d.txt', encoding=\"utf8\")\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUhsIFAIw2Ah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_size, 50))\n",
        "for word, i in t.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98mHVIe61GYu",
        "colab_type": "text"
      },
      "source": [
        "**Creating the LSTM layer architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXBsWx44w6OI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Embedding, Flatten, Dense, LSTM, Dropout\n",
        "from keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daT--LdGxA67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "filepath=\"model.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='acc', save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4LeUN-WxEFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "e = Embedding(vocab_size, 50, weights=[embedding_matrix], input_length = 25, trainable=True)\n",
        "model.add(e)\n",
        "model.add(LSTM(128,activation = 'tanh', return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128,activation = 'tanh', return_sequences=True))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(128,activation = 'tanh', return_sequences=False))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(5, activation = 'softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk1HCmsuzs49",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "1c34037f-e6c9-4eb1-8b3e-85b0bb3a9e30"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 25, 50)            13050     \n",
            "_________________________________________________________________\n",
            "lstm_10 (LSTM)               (None, 25, 128)           91648     \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 25, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_11 (LSTM)               (None, 25, 128)           131584    \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 25, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_12 (LSTM)               (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 368,511\n",
            "Trainable params: 368,511\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxMMA49kxJjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62F6F8twxOuk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3b6219c5-d279-4d89-869e-5149517dd470"
      },
      "source": [
        "model.fit(x_train_padded, y_train, epochs = 100, batch_size = 512,callbacks = callbacks_list,validation_data=(x_cv,y_cv))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 100 samples, validate on 32 samples\n",
            "Epoch 1/100\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 1.6067 - acc: 0.2300 - val_loss: 1.5979 - val_acc: 0.2188\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.5807 - acc: 0.2800 - val_loss: 1.5981 - val_acc: 0.2188\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.5516 - acc: 0.3100 - val_loss: 1.6292 - val_acc: 0.2188\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.5229 - acc: 0.2900 - val_loss: 1.6946 - val_acc: 0.2188\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.5347 - acc: 0.3300 - val_loss: 1.6660 - val_acc: 0.3125\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.4807 - acc: 0.3900 - val_loss: 1.6235 - val_acc: 0.3438\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.4640 - acc: 0.3800 - val_loss: 1.5745 - val_acc: 0.2812\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.4426 - acc: 0.4000 - val_loss: 1.5224 - val_acc: 0.3750\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.3887 - acc: 0.4700 - val_loss: 1.4572 - val_acc: 0.3438\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.3214 - acc: 0.4700 - val_loss: 1.3645 - val_acc: 0.4375\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.2147 - acc: 0.4800 - val_loss: 1.2961 - val_acc: 0.5000\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.1870 - acc: 0.5000 - val_loss: 1.2979 - val_acc: 0.4375\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.0829 - acc: 0.5300 - val_loss: 1.2185 - val_acc: 0.5625\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.9744 - acc: 0.6400 - val_loss: 1.1770 - val_acc: 0.6250\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.9134 - acc: 0.6500 - val_loss: 1.1533 - val_acc: 0.6250\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.8869 - acc: 0.6800 - val_loss: 1.0634 - val_acc: 0.5625\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.7972 - acc: 0.7200 - val_loss: 0.9684 - val_acc: 0.6562\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.7549 - acc: 0.7200 - val_loss: 0.8181 - val_acc: 0.6250\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.7092 - acc: 0.7100 - val_loss: 0.8268 - val_acc: 0.6875\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6089 - acc: 0.7800 - val_loss: 0.8013 - val_acc: 0.6875\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5355 - acc: 0.7700 - val_loss: 0.6509 - val_acc: 0.8125\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5624 - acc: 0.8400 - val_loss: 0.6567 - val_acc: 0.7812\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.4378 - acc: 0.8200 - val_loss: 0.7634 - val_acc: 0.7188\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.4743 - acc: 0.8200 - val_loss: 0.6520 - val_acc: 0.7812\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.4556 - acc: 0.8300 - val_loss: 0.6593 - val_acc: 0.7812\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.3145 - acc: 0.9000 - val_loss: 0.7989 - val_acc: 0.6875\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.3101 - acc: 0.8700 - val_loss: 0.7226 - val_acc: 0.7500\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2418 - acc: 0.9200 - val_loss: 0.7086 - val_acc: 0.8125\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2428 - acc: 0.9000 - val_loss: 0.7165 - val_acc: 0.7812\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1987 - acc: 0.9300 - val_loss: 0.7945 - val_acc: 0.7500\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1959 - acc: 0.9200 - val_loss: 0.7350 - val_acc: 0.7812\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1297 - acc: 0.9800 - val_loss: 0.7987 - val_acc: 0.8125\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1738 - acc: 0.9500 - val_loss: 0.7825 - val_acc: 0.7500\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0857 - acc: 1.0000 - val_loss: 0.9772 - val_acc: 0.7500\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2379 - acc: 0.9300 - val_loss: 0.7185 - val_acc: 0.7812\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0575 - acc: 0.9900 - val_loss: 1.0334 - val_acc: 0.7812\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2314 - acc: 0.9200 - val_loss: 0.8537 - val_acc: 0.7812\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0404 - acc: 1.0000 - val_loss: 0.8264 - val_acc: 0.7812\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0709 - acc: 0.9800 - val_loss: 0.8997 - val_acc: 0.7500\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0885 - acc: 0.9900 - val_loss: 0.9209 - val_acc: 0.7812\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0710 - acc: 0.9800 - val_loss: 0.7866 - val_acc: 0.8125\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0296 - acc: 1.0000 - val_loss: 0.6749 - val_acc: 0.8438\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0216 - acc: 1.0000 - val_loss: 0.7638 - val_acc: 0.8125\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0142 - acc: 1.0000 - val_loss: 0.8831 - val_acc: 0.7812\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0207 - acc: 0.9900 - val_loss: 0.9848 - val_acc: 0.7500\n",
            "Epoch 46/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0117 - acc: 1.0000 - val_loss: 1.0779 - val_acc: 0.7188\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 1.1434 - val_acc: 0.6875\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 1.2040 - val_acc: 0.7188\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 1.2907 - val_acc: 0.7188\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0105 - acc: 1.0000 - val_loss: 1.1929 - val_acc: 0.7500\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0097 - acc: 1.0000 - val_loss: 1.0548 - val_acc: 0.7812\n",
            "Epoch 52/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0094 - acc: 1.0000 - val_loss: 1.1441 - val_acc: 0.7188\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 1.2835 - val_acc: 0.7188\n",
            "Epoch 54/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 1.3357 - val_acc: 0.7188\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 1.3887 - val_acc: 0.7188\n",
            "Epoch 56/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 1.4731 - val_acc: 0.6562\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0113 - acc: 1.0000 - val_loss: 1.4517 - val_acc: 0.7188\n",
            "Epoch 58/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 1.4778 - val_acc: 0.7188\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 1.5078 - val_acc: 0.7188\n",
            "Epoch 60/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 1.5343 - val_acc: 0.7188\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 1.5564 - val_acc: 0.7188\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 1.5722 - val_acc: 0.7188\n",
            "Epoch 63/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 1.5786 - val_acc: 0.7188\n",
            "Epoch 64/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 1.5694 - val_acc: 0.7188\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 1.5412 - val_acc: 0.7188\n",
            "Epoch 66/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 1.5124 - val_acc: 0.7500\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 1.5154 - val_acc: 0.7500\n",
            "Epoch 68/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 1.5297 - val_acc: 0.7500\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 1.5450 - val_acc: 0.7500\n",
            "Epoch 70/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 1.5607 - val_acc: 0.7500\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 1.5769 - val_acc: 0.7188\n",
            "Epoch 72/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 1.5929 - val_acc: 0.7188\n",
            "Epoch 73/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 1.6083 - val_acc: 0.7188\n",
            "Epoch 74/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 1.6230 - val_acc: 0.7188\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 1.6370 - val_acc: 0.7188\n",
            "Epoch 76/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 1.6503 - val_acc: 0.7188\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 1.6620 - val_acc: 0.7188\n",
            "Epoch 78/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 1.6724 - val_acc: 0.7188\n",
            "Epoch 79/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 1.6813 - val_acc: 0.7188\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 1.6885 - val_acc: 0.7188\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 1.6938 - val_acc: 0.7188\n",
            "Epoch 82/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 1.6976 - val_acc: 0.7188\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 1.7006 - val_acc: 0.7188\n",
            "Epoch 84/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 1.7035 - val_acc: 0.7188\n",
            "Epoch 85/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 1.7068 - val_acc: 0.7188\n",
            "Epoch 86/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 1.7101 - val_acc: 0.7188\n",
            "Epoch 87/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 1.7133 - val_acc: 0.7188\n",
            "Epoch 88/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 1.7172 - val_acc: 0.7188\n",
            "Epoch 89/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 1.7208 - val_acc: 0.7188\n",
            "Epoch 90/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 1.7244 - val_acc: 0.7188\n",
            "Epoch 91/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 1.7277 - val_acc: 0.7188\n",
            "Epoch 92/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 1.7309 - val_acc: 0.7188\n",
            "Epoch 93/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 1.7340 - val_acc: 0.7188\n",
            "Epoch 94/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 1.7370 - val_acc: 0.7188\n",
            "Epoch 95/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.7401 - val_acc: 0.7188\n",
            "Epoch 96/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 1.7429 - val_acc: 0.7188\n",
            "Epoch 97/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.7455 - val_acc: 0.7188\n",
            "Epoch 98/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 1.7481 - val_acc: 0.7188\n",
            "Epoch 99/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 1.7511 - val_acc: 0.7188\n",
            "Epoch 100/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.7541 - val_acc: 0.7188\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fa95aa6f9b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrH6sv9e6HCJ",
        "colab_type": "text"
      },
      "source": [
        "**Preparing test data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8m5CrOFS2iLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = Tokenizer()\n",
        "t.fit_on_texts(test[0])\n",
        "vocab_size = len(t.word_index) + 1\n",
        "encoded = t.texts_to_sequences(test[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O71UglMhyAK3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "5723acf8-eeae-4f2e-e487-5fd42a96cb6b"
      },
      "source": [
        "padded = pad_sequences(encoded, maxlen=25, padding='post')\n",
        "print(padded[:2])"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1 23  9 46  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0]\n",
            " [10 11 12 47  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFaEwQr72wbi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "604736a6-824f-4782-8410-4921eb83ab19"
      },
      "source": [
        "x_test_padded=padded[:]\n",
        "print(x_test_padded.shape)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(56, 25)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMGvgjlP21Aj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3a97f115-771e-4af3-9100-9138b5a0bc95"
      },
      "source": [
        "model.evaluate(x_test_padded,y_test)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56/56 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6.52942909513201, 0.1964285671710968]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tf_lls653H3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict_classes(x_test_padded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21-16Lcb4zkY",
        "colab_type": "text"
      },
      "source": [
        "**Predicted emoji matched with actual emoji**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6nFraJ83XQh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "fb8aa6b0-c6b6-4af3-f368-99fb43320ed2"
      },
      "source": [
        "for i in range(10):\n",
        "    print(' '.join(train[0][i]))\n",
        "    print(emoji.emojize(emoji_dictionary[str(np.argmax(y_test[i]))])) #Printing the actual emoji\n",
        "    print(emoji.emojize(emoji_dictionary[str(pred[i])])) # Printing the predicted emoji\n"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "never talk to me again\n",
            "🍴\n",
            "😁\n",
            "I am proud of your achievements\n",
            "😓\n",
            "😓\n",
            "I t   i s   t h e   w o r s t   d a y   i n   m y   l i f e\n",
            "😁\n",
            "❤️\n",
            "M i s s   y o u   s o   m u c h\n",
            "❤️\n",
            "😁\n",
            "f o o d   i s   l i f e\n",
            "😁\n",
            "😁\n",
            "I   l o v e   y o u   m u m\n",
            "❤️\n",
            "😓\n",
            "S t o p   s a y i n g   b u l l s h i t\n",
            "❤️\n",
            "😓\n",
            "c o n g r a t u l a t i o n s   o n   y o u r   a c c e p t a n c e\n",
            "❤️\n",
            "😁\n",
            "T h e   a s s i g n m e n t   i s   t o o   l o n g\n",
            "🍴\n",
            "❤️\n",
            "I   w a n t   t o   g o   p l a y\n",
            "😁\n",
            "😓\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Hb_Y3zP5YMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}